{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(0)\n",
    "\n",
    "def percentage_change(old, new):\n",
    "    return abs(new - old) / old if old != 0 else 0\n",
    "\n",
    "def is_bounding_box_stable(previous_face, current_face, tolerance=0.10):\n",
    "    x1_prev, y1_prev, x2_prev, y2_prev = previous_face\n",
    "    x1_curr, y1_curr, x2_curr, y2_curr = current_face\n",
    "    \n",
    "    # Calculate changes in coordinates and size\n",
    "    width_change = percentage_change(x2_prev - x1_prev, x2_curr - x1_curr)\n",
    "    height_change = percentage_change(y2_prev - y1_prev, y2_curr - y1_curr)\n",
    "    position_change_x = percentage_change(x1_prev, x1_curr)\n",
    "    position_change_y = percentage_change(y1_prev, y1_curr)\n",
    "\n",
    "    width_change = 0\n",
    "    height_change = 0\n",
    "\n",
    "    # Return True if changes are within tolerance\n",
    "    return all(change < tolerance for change in [width_change, height_change, position_change_x, position_change_y])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to process a single frame of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, faces, action=\"crop\"):\n",
    "    for face in faces:\n",
    "        # Get bounding box coordinates\n",
    "        x1, y1, x2, y2 = face.left(), face.top(), face.right(), face.bottom()\n",
    "\n",
    "        # Find the center of the bounding box and size\n",
    "        center_x = (x1 + x2) // 2\n",
    "        center_y = (y1 + y2) // 2\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "\n",
    "        margin_x = int(0.2 * (x2 - x1))  # Reduce the width by 20%\n",
    "        margin_y = int(0.2 * (y2 - y1))  # Reduce the height by 20%\n",
    "\n",
    "        # Crop the face from the frame\n",
    "        if action == \"crop\":\n",
    "            # Adjust the coordinates inward by the margin\n",
    "            x1 = max(0, x1 + margin_x)\n",
    "            y1 = max(0, y1 + margin_y)\n",
    "            x2 = min(frame.shape[1], x2 - margin_x)\n",
    "            y2 = min(frame.shape[0], y2 - margin_y)\n",
    "            \n",
    "            cropped_face = frame[y1:y2, x1:x2]\n",
    "            if cropped_face.size == 0:\n",
    "                return None  # Return None if cropping failed\n",
    "            \n",
    "            # Resize the face to original size of the frame\n",
    "            resized_face = cv2.resize(cropped_face, (frame.shape[1], frame.shape[0]))\n",
    "            return resized_face\n",
    "\n",
    "        # Put an ellipsoid on the face and mask only the face\n",
    "        elif action == \"mask\":\n",
    "            # Create a full white mask (the same size as the frame)\n",
    "            mask = np.ones_like(frame) * 255\n",
    "\n",
    "            # Draw a black ellipsoid to cover the face (inverse mask)\n",
    "            cv2.ellipse(mask, (center_x, center_y), (width // 3  + width // 10 , height // 2 + height // 6), 0, 0, 360, (0, 0, 0), -1)\n",
    "\n",
    "            # Apply the mask to the original frame using bitwise AND\n",
    "            masked_frame = cv2.bitwise_and(frame, mask)\n",
    "\n",
    "            return masked_frame\n",
    "\n",
    "    return frame  # Return original frame if no face is detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to process an entire video with the previous function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(input_video, output_video, action=\"crop\"):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(input_video)\n",
    "\n",
    "    # Check if the video was opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {input_video}\")\n",
    "        return\n",
    "\n",
    "    # Get video properties\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video_duration = total_frames / fps\n",
    "\n",
    "    #print(f\"Video properties: {frame_width}x{frame_height} at {fps} FPS with duration {video_duration}\")\n",
    "\n",
    "    # Define the codec and create a VideoWriter object (using 'XVID' for .avi)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # XVID codec for AVI\n",
    "    out = cv2.VideoWriter(output_video, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    # Find a stable 10-second window\n",
    "    stable_segment_found = False\n",
    "\n",
    "\n",
    "    found_times = []\n",
    "    for i in range(int(video_duration//10)*2):\n",
    "        # Every 5 seconds\n",
    "        start_time = i * 5\n",
    "\n",
    "        print(f\"Trying with start time of {start_time} seconds\")\n",
    "        # Randomly pick a start time for the 10-second window if specified\n",
    "        #print(f\"Trying with start time of {start_time} seconds\")\n",
    "        cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)  # Seek to the start time\n",
    "\n",
    "        previous_face = None\n",
    "        stable_segment = True\n",
    "        frames_to_process = int(10 * fps)\n",
    "\n",
    "        for _ in range(frames_to_process):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                #print(\"End of video or can't read frame.\")\n",
    "                stable_segment = False\n",
    "                break  # End of video\n",
    "\n",
    "            # Convert frame to grayscale for face detection\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect faces in the frame\n",
    "            faces = detector(gray)\n",
    "\n",
    "            # Ensure at least one face is detected\n",
    "            if len(faces) == 0:\n",
    "                stable_segment = False\n",
    "                break\n",
    "\n",
    "            # Get current face bounding box\n",
    "            current_face = (faces[0].left(), faces[0].top(), faces[0].right(), faces[0].bottom())\n",
    "\n",
    "            if previous_face is not None:\n",
    "                # Check if the bounding box is stable compared to the previous frame\n",
    "                if not is_bounding_box_stable(previous_face, current_face):\n",
    "                    stable_segment = False\n",
    "                    #print(f\"The segment {start_time} to {start_time + 10} was not stable\")\n",
    "                    break\n",
    "\n",
    "            # Update previous face to current\n",
    "            previous_face = current_face\n",
    "        \n",
    "        \n",
    "        # If stable segment found, process it\n",
    "        if stable_segment:\n",
    "            print(f\"Stable segment found at {start_time:.2f} - {start_time + 10:.2f} seconds.\")\n",
    "            if action == 'extract_time_segment':\n",
    "                found_times.append(start_time)\n",
    "                continue\n",
    "             \n",
    "            stable_segment_found = True\n",
    "            cap.set(cv2.CAP_PROP_POS_MSEC, start_time * 1000)  # Seek back to start of segment\n",
    "\n",
    "            # Process the 10-second stable window\n",
    "            for _ in range(frames_to_process):\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break  # End of video\n",
    "\n",
    "                # Convert frame to grayscale for face detection\n",
    "                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Detect faces in the frame\n",
    "                faces = detector(gray)\n",
    "\n",
    "                # Process frame based on the selected action\n",
    "                processed_frame = process_frame(frame, faces, action)\n",
    "                if processed_frame is not None:\n",
    "                    out.write(processed_frame)  # Write processed frame to output video\n",
    "                else:\n",
    "                    out.write(frame)  # Write original frame if face detection/cropping failed\n",
    "\n",
    "            break  # Stop after processing a stable segment\n",
    "    \n",
    "    if action == 'extract_time_segment':\n",
    "        return found_times\n",
    "\n",
    "    if not stable_segment_found:\n",
    "        print(\"Could not find a stable 10-second segment after retries.\")\n",
    "\n",
    "    # Release everything, because we are done and we need to close the output file\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(f\"Processing complete. Output saved as {output_video}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' FOR ALL OF THEM\\nfor i in range(1, 14):\\n    input_video = f\"../Experiment_videos/s_sj{i}_EO.avi\"\\n    for _ in range(13):\\n        start_time = process_video(input_video, output_video_crop, start_time=0, found_times=times, action=\\'extract_time_segment\\')\\n        if start_time is None:\\n            break\\n        times.append(start_time)\\n    \\n    print(f\"Times for person {i}\")\\n    \\n    print(times)\\n    times = []\\n\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_video = \"../Experiment_videos/s_sj1_EO.avi\"\n",
    "output_video_crop = \"output_cropped.mp4\"\n",
    "output_video_ellipsoid = \"output_ellipsoid.mp4\"\n",
    "\n",
    "\n",
    "\n",
    "# Crop the face in the video\n",
    "#process_video(input_video, output_video_crop, action=\"crop\")\n",
    "\n",
    "# Apply an ellipsoid mask to the face in the video\n",
    "#process_video(input_video, output_video_ellipsoid, action=\"mask\")\n",
    "\n",
    "times=[]\n",
    "\"\"\" FOR ALL OF THEM\n",
    "for i in range(1, 14):\n",
    "    input_video = f\"../Experiment_videos/s_sj{i}_EO.avi\"\n",
    "    for _ in range(13):\n",
    "        start_time = process_video(input_video, output_video_crop, start_time=0, found_times=times, action='extract_time_segment')\n",
    "        if start_time is None:\n",
    "            break\n",
    "        times.append(start_time)\n",
    "    \n",
    "    print(f\"Times for person {i}\")\n",
    "    \n",
    "    print(times)\n",
    "    times = []\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying with start time of 0 seconds\n",
      "Stable segment found at 0.00 - 10.00 seconds.\n",
      "Trying with start time of 5 seconds\n",
      "Stable segment found at 5.00 - 15.00 seconds.\n",
      "Trying with start time of 10 seconds\n",
      "Stable segment found at 10.00 - 20.00 seconds.\n",
      "Trying with start time of 15 seconds\n",
      "Stable segment found at 15.00 - 25.00 seconds.\n",
      "Trying with start time of 20 seconds\n",
      "Stable segment found at 20.00 - 30.00 seconds.\n",
      "Trying with start time of 25 seconds\n",
      "Stable segment found at 25.00 - 35.00 seconds.\n",
      "Trying with start time of 30 seconds\n",
      "Stable segment found at 30.00 - 40.00 seconds.\n",
      "Trying with start time of 35 seconds\n",
      "Stable segment found at 35.00 - 45.00 seconds.\n",
      "Trying with start time of 40 seconds\n",
      "Stable segment found at 40.00 - 50.00 seconds.\n",
      "Trying with start time of 45 seconds\n",
      "Stable segment found at 45.00 - 55.00 seconds.\n",
      "Trying with start time of 50 seconds\n",
      "Stable segment found at 50.00 - 60.00 seconds.\n",
      "Trying with start time of 55 seconds\n",
      "Stable segment found at 55.00 - 65.00 seconds.\n",
      "Trying with start time of 60 seconds\n",
      "Stable segment found at 60.00 - 70.00 seconds.\n",
      "Trying with start time of 65 seconds\n",
      "Stable segment found at 65.00 - 75.00 seconds.\n",
      "Trying with start time of 70 seconds\n",
      "Stable segment found at 70.00 - 80.00 seconds.\n",
      "Trying with start time of 75 seconds\n",
      "Stable segment found at 75.00 - 85.00 seconds.\n",
      "Trying with start time of 80 seconds\n",
      "Stable segment found at 80.00 - 90.00 seconds.\n",
      "Trying with start time of 85 seconds\n",
      "Stable segment found at 85.00 - 95.00 seconds.\n",
      "Trying with start time of 90 seconds\n",
      "Stable segment found at 90.00 - 100.00 seconds.\n",
      "Trying with start time of 95 seconds\n",
      "Stable segment found at 95.00 - 105.00 seconds.\n",
      "Trying with start time of 100 seconds\n",
      "Stable segment found at 100.00 - 110.00 seconds.\n",
      "Trying with start time of 105 seconds\n",
      "Stable segment found at 105.00 - 115.00 seconds.\n",
      "Trying with start time of 110 seconds\n",
      "Stable segment found at 110.00 - 120.00 seconds.\n",
      "Trying with start time of 115 seconds\n",
      "Times for person 12\n",
      "[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110]\n"
     ]
    }
   ],
   "source": [
    "# FOR SINGLE PERSON\n",
    "person = 13\n",
    "input_video = f\"../Experiment_videos/s_sj{person}_EO.avi\"\n",
    "times = process_video(input_video, output_video_crop, action='extract_time_segment')\n",
    "print(f\"Times for person {person}\")\n",
    "\n",
    "print(times)\n",
    "times = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
